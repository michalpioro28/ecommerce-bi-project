{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9223d4e3",
   "metadata": {},
   "source": [
    "# Data Audit – Notebook\n",
    "\n",
    "**Uwaga**  \n",
    "Ten notatnik pełni rolę *„brudnopisu”* – pokazuje proces audytu danych krok po kroku.  \n",
    "Kod i wykresy w tym notebooku mają charakter roboczy i nie są dopracowane pod względem estetycznym.  \n",
    "\n",
    "Estetyczne i finalne wersje wyników znajdują się w:  \n",
    "- `scripts/data_audit.py` - czysty, uporządkowany kod,  \n",
    "- `reports/audit_full.txt` oraz `reports/audit_extended.txt` - finalne raporty tekstowe z audytu.  \n",
    "\n",
    "Celem tego notatnika jest **pokazanie procesu sprawdzania jakości danych**, w tym:  \n",
    "- testy spójności i integralności między tabelami,  \n",
    "- sprawdzanie unikalności kluczy głównych,  \n",
    "- sprawdzanie wartości (np. brak NULL),  \n",
    "- wykrywanie anomalii."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1896e43",
   "metadata": {},
   "source": [
    "## Importy i konfiguracjja środowiska\n",
    "\n",
    "W tej komórce importujemy niezbędne biblioteki:\n",
    "\n",
    "- `os` - do operacji na systemie plików i zmiennych środowiskowych,\n",
    "- `pandas` - do pracy z danymi w formie DataFrame,\n",
    "- `dotenv` - do wczytywania zmiennych środowiskowych z pliku `.env`,\n",
    "- `sqlalchemy` - do łączenia się z bazą danych i wykonywania zapytań SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923882b2",
   "metadata": {},
   "source": [
    "## Wczytywanie zmiennych środowiskowych\n",
    "\n",
    "Wczytujemy dane do logowania do bazy z pliku `.env`, żeby nie trzymać haseł bezpośrednio w kodzie.  \n",
    "\n",
    "Zmienne w `.env`:\n",
    "\n",
    "- `DB_HOST` - adres serwera bazy,\n",
    "- `DB_NAME` - nazwa bazy danych,\n",
    "- `DB_USER` - użytkownik bazy,\n",
    "- `DB_PASS` - hasło użytkownika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba849641",
   "metadata": {},
   "source": [
    "## Połączenie z bazą danych\n",
    "\n",
    "Tworzymy połączenie do bazy danych PostgreSQL przy użyciu `SQLAlchemy`.  \n",
    "Dzięki temu możemy wykonywać zapytania SQL bezpośrednio w Pythonie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    version = conn.execute(text(\"SELECT version()\")).scalar()\n",
    "    print(f\"Połączono z bazą. Wersja PostgreSQL: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59be624",
   "metadata": {},
   "source": [
    "## Lista tabel w schemacie `public`\n",
    "\n",
    "W tej części pobieramy wszystkie tabele ze schematu `public`, aby wiedzieć które tabele trzeba poddać audytowi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb09544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_sql(\n",
    "    \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\",\n",
    "    engine\n",
    ")[\"table_name\"].tolist()\n",
    "\n",
    "print(f\"\\nZnaleziono {len(tables)} tabel: {tables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c11d51",
   "metadata": {},
   "source": [
    "## Folder na raporty audytu\n",
    "\n",
    "Tworzymy folder `data/audit_reports`, gdzie będą zapisywane pliki CSV z wynikami audytu.  \n",
    "Funkcja `os.makedirs(..., exist_ok=True)` zapewnia, że folder zostanie utworzony tylko jeśli jeszcze nie istnieje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"data/audit_reports\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb869e",
   "metadata": {},
   "source": [
    "## Audyt tabel\n",
    "\n",
    "Dla każdej tabeli wykonujemy:\n",
    "\n",
    "1. Podgląd 5 pierwszych wierszy (`preview`),\n",
    "2. Zliczenie wszystkich wierszy (`row_count`),\n",
    "3. Sprawdzenie braków danych (`NULL`) w podglądzie,\n",
    "4. Sprawdzenie unikalności wartości i nietypowych znaków (np. średników) w danych,\n",
    "5. Zapis wyników do zbiorczego raportu.\n",
    "\n",
    "Każda tabela jest analizowana osobno, a wyniki są zbierane w liście `all_tables_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e28bfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m all_tables_report = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtables\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Audyt tabeli: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     preview = pd.read_sql(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSELECT * FROM \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m LIMIT 5\u001b[39m\u001b[33m'\u001b[39m, engine)\n",
      "\u001b[31mNameError\u001b[39m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "all_tables_report = []\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"\\n=== Audyt tabeli: {table} ===\")\n",
    "    preview = pd.read_sql(f'SELECT * FROM \"{table}\" LIMIT 5', engine)\n",
    "    print(preview)\n",
    "    \n",
    "    row_count = pd.read_sql(f'SELECT COUNT(*) FROM \"{table}\"', engine).iloc[0, 0]\n",
    "    print(f\"Liczba wierszy: {row_count}\")\n",
    "    \n",
    "    null_counts = preview.isnull().sum()\n",
    "    print(\"\\nBraki danych (NULL):\")\n",
    "    print(null_counts)\n",
    "    \n",
    "    uwagi = []\n",
    "    for col in preview.columns:\n",
    "        if preview[col].nunique(dropna=True) == len(preview):\n",
    "            uwagi.append(f\"Kolumna '{col}' ma unikalne wartości w podglądzie\")\n",
    "        if any(\";\" in str(v) for v in preview[col].dropna()):\n",
    "            uwagi.append(f\"Kolumna '{col}' zawiera średnik w danych\")\n",
    "    \n",
    "    all_tables_report.append({\n",
    "        \"tabela\": table,\n",
    "        \"wiersze\": row_count,\n",
    "        \"braki_NULL\": null_counts.to_dict(),\n",
    "        \"uwagi\": \"; \".join(uwagi) if uwagi else \"\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ce593",
   "metadata": {},
   "source": [
    "## Zapis raportu zbiorczego\n",
    "\n",
    "Tworzymy dataframe z listy raportów, a następnie zapisujemy go jako CSV w folderze `data/audit_reports` pod nazwą `audit_summary.csv`.  \n",
    "\n",
    "Plik zawiera:\n",
    "\n",
    "- nazwę tabeli,\n",
    "- liczbę wierszy,\n",
    "- braki danych (`NULL`) w podglądzie,\n",
    "- uwagi dotyczące unikalności kolumn i innych anomalii w danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(all_tables_report)\n",
    "report_path = os.path.join(out_dir, \"audit_summary.csv\")\n",
    "report_df.to_csv(report_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nAudyt zakończony. Raport zapisany do: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e5ec0",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "\n",
    "Po wykonaniu audytu mamy pełny raport wszystkich tabel, który możemy wykorzystać do dalszego czyszczenia i analiz danych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
